{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"results/topic_info_df.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Replace missing values with an empty string, then count tokens by splitting on whitespace\n",
    "df[\"token_count\"] = df[\"Representative_Docs\"].fillna(\"\").apply(lambda x: len(x.split()))\n",
    "\n",
    "# Get the maximum number of tokens in any single document\n",
    "max_tokens = df[\"token_count\"].max()\n",
    "print(f\"Maximum number of tokens in a single document: {max_tokens}\")\n",
    "\n",
    "# Display the documents with their corresponding token counts\n",
    "print(df[[\"Representative_Docs\", \"token_count\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Initialize LLM (GPT-4o mini)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=50\n",
    ")\n",
    "\n",
    "# Prompt Template\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a topic modeling assistant. Given the following information:\n",
    "\n",
    "Name: {name}\n",
    "Representation: {representation}\n",
    "Representative Document: {document}\n",
    "\n",
    "Generate a concise topic title that best summarizes the content above. The topic should be no more than 10 words. Return only the topic title.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "topics = []\n",
    "\n",
    "# Iterate through each row (or use batch in next step)\n",
    "for i, row in df.iterrows():\n",
    "    name = row.get(\"Name\", \"\")\n",
    "    representation = row.get(\"Representation\", \"\")\n",
    "    document = \" \".join(str(row.get(\"Representative_Docs\", \"\")))  \n",
    "\n",
    "    try:\n",
    "        result = chain.run({\n",
    "            \"name\": name,\n",
    "            \"representation\": representation,\n",
    "            \"document\": document\n",
    "        })\n",
    "        topics.append(result.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        topics.append(\"[ERROR]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "df[\"GPT_topic\"] = topics\n",
    "df.to_csv(\"results/topic_info_with_topics_GPT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GPT_topic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['GPT_topic'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
